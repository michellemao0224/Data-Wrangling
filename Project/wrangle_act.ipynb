{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Tweeter Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "if r.status_code == 200:\n",
    "    with open('image_predictions.tsv', 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pd.read_csv('image_predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "consumer_key = 'X4Mu5bFyMBpjjstVS4XbYjZcL'\n",
    "consumer_secret = '6nXJBPj6kBPzT0zP45fZnjiAOuMTN5OEBS3tQ7xKbfIT4NuIst'\n",
    "access_token = '4366384514-l6MKA0qiPnv018rq4aSQPQd5TODG6Ko4gNeBlSA'\n",
    "access_secret = '6HcJzhQoY9fZaTfj8p5XXyBdCjNsKiB8SUURkRmSQEh3H'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 256\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Rate limit reached. Sleeping for: 732\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "1383.16354203\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "tweet_id = []\n",
    "retweet_count = []\n",
    "favorite_count = []\n",
    "\n",
    "for ids in image.tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(ids, tweet_mode='extended')\n",
    "        tweet_id.append(ids)\n",
    "        retweet_count.append(tweet.retweet_count)\n",
    "        favorite_count.append(tweet.favorite_count)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "end = timer()\n",
    "print(end - start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "file = open(\"tweet_json.txt\", \"w\")\n",
    "for index in range(len(tweet_id)):\n",
    "    file.write(str(tweet_id[index]) + \" \" + str(retweet_count[index]) + \" \" + str(favorite_count[index]) + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('tweet_json.txt', sep=\" \", header=None)\n",
    "info.columns = ['tweet_id','retweet_count','favorite_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>519</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>47</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>45</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>141</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>40</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>666050758794694657</td>\n",
       "      <td>59</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>666051853826850816</td>\n",
       "      <td>864</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>666055525042405380</td>\n",
       "      <td>258</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>666057090499244032</td>\n",
       "      <td>143</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>666058600524156928</td>\n",
       "      <td>58</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  retweet_count  favorite_count\n",
       "0  666020888022790149            519            2521\n",
       "1  666029285002620928             47             131\n",
       "2  666033412701032449             45             125\n",
       "3  666044226329800704            141             302\n",
       "4  666049248165822465             40             109\n",
       "5  666050758794694657             59             133\n",
       "6  666051853826850816            864            1236\n",
       "7  666055525042405380            258             441\n",
       "8  666057090499244032            143             299\n",
       "9  666058600524156928             58             114"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = pd.Series(list(tweet)+ list(image))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet[tweet['expanded_urls'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet[tweet.name.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet.rating_numerator.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.rating_denominator.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet[(tweet['doggo'] == 'doggo')]) + len(tweet[(tweet['floofer'] == 'floofer')])  + len(tweet[(tweet['pupper'] == 'pupper')]) \n",
    "+ len(tweet[(tweet['puppo'] == 'puppo')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "##### `patients` table\n",
    "- Zip code is a float not a string\n",
    "- Zip code has four digits sometimes\n",
    "- Tim Neudorf height is 27 in instead of 72 in\n",
    "- Full state names sometimes, abbreviations other times\n",
    "- Dsvid Gustafsson\n",
    "- Missing demographic information (address - contact columns) ***(can't clean)***\n",
    "- Erroneous datatypes (assigned sex, state, zip_code, and birthdate columns)\n",
    "- Multiple phone number formats\n",
    "- Default John Doe data\n",
    "- Multiple records for Jakobsen, Gersten, Taylor\n",
    "- kgs instead of lbs for Zaitseva weight\n",
    "\n",
    "##### `treatments` table\n",
    "- Missing HbA1c changes\n",
    "- The letter 'u' in starting and ending doses for Auralin and Novodra\n",
    "- Lowercase given names and surnames\n",
    "- Missing records (280 instead of 350)\n",
    "- Erroneous datatypes (auralin and novodra columns)\n",
    "- Inaccurate HbA1c changes (leading 4s mistaken as 9s)\n",
    "- Nulls represented as dashes (-) in auralin and novodra columns\n",
    "\n",
    "##### `adverse_reactions` table\n",
    "- Lowercase given names and surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness\n",
    "- Contact column in `patients` table should be split into phone number and email\n",
    "- Three variables in two columns in `treatments` table (treatment, start dose and end dose)\n",
    "- Adverse reaction should be part of the `treatments` table\n",
    "- Given name and surname columns in `patients` table duplicated in `treatments` and `adverse_reactions` tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients_clean = patients.copy()\n",
    "treatments_clean = treatments.copy()\n",
    "adverse_reactions_clean = adverse_reactions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Complete the following two \"Missing Data\" **Define, Code, and Test** sequences after watching the *\"Address Missing Data First\"* video.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `treatments`: Missing records (280 instead of 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Note: the missing `treatments` records are stored in a file named `treatments_cut.csv`, which you can see in this Jupyter Notebook's dashboard (click the **jupyter** logo in the top lefthand corner of this Notebook). Hint: [documentation page](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html) for the function used in the solution.*\n",
    "\n",
    "Import the cut treatments into a DataFrame and concatenate it with the original treatments DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "treatments_cut = pd.read_csv('treatments_cut.csv')\n",
    "treatments_clean = pd.concat([treatments_clean, treatments_cut],\n",
    "                             ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "treatments_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `treatments`: Missing HbA1c changes and Inaccurate HbA1c changes (leading 4s mistaken as 9s)\n",
    "*Note: the \"Inaccurate HbA1c changes (leading 4s mistaken as 9s)\" observation, which is an accuracy issue and not a completeness issue, is included in this header because it is also fixed by the cleaning operation that fixes the missing \"Missing HbA1c changes\" observation. Multiple observations in one **Define, Code, and Test** header occurs multiple times in this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here.*\n",
    "\n",
    "Recalculate the hba1c_change column: hba1c_start minus hba1c_end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "treatments_clean.hba1c_change = (treatments_clean.hba1c_start - \n",
    "                                 treatments_clean.hba1c_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "treatments_clean.hba1c_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Complete the following four \"Tidiness\" **Define, Code, and Test** sequences after watching the *\"Cleaning for Tidiness\"* video.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contact column in `patients` table contains two variables: phone number and email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint 1: use regular expressions with pandas' [`str.extract` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.extract.html). Here is an amazing [regex tutorial](https://regexone.com/). Hint 2: [various phone number regex patterns](https://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number). Hint 3: [email address regex pattern](http://emailregex.com/), which you might need to modify to distinguish the email from the phone number.*\n",
    "\n",
    "Extract the phone number and email variables from the contact column using regular expressions and pandas' str.extract method. Drop the contact column when done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean['phone_number'] = patients_clean.contact.str.extract('((?:\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4})', expand=True)\n",
    "\n",
    "# [a-zA-Z] to signify emails in this dataset all start and end with letters\n",
    "patients_clean['email'] = patients_clean.contact.str.extract('([a-zA-Z][a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+[a-zA-Z])', expand=True)\n",
    "\n",
    "# Note: axis=1 denotes that we are referring to a column, not a row\n",
    "patients_clean = patients_clean.drop('contact', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "\n",
    "# Confirm contact column is gone\n",
    "list(patients_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean.phone_number.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that no emails start with an integer (regex didn't match for this)\n",
    "patients_clean.email.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three variables in two columns in `treatments` table (treatment, start dose and end dose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: use pandas' [melt function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html) and [`str.split()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html). Here is an excellent [`melt` tutorial](https://deparkes.co.uk/2016/10/28/reshape-pandas-data-with-melt/).*\n",
    "\n",
    "Melt the auralin and novodra columns to a treatment and a dose column (dose will still contain both start and end dose at this point). Then split the dose column on ' - ' to obtain start_dose and end_dose columns. Drop the intermediate dose column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "treatments_clean = pd.melt(treatments_clean, id_vars=['given_name', 'surname', 'hba1c_start', 'hba1c_end', 'hba1c_change'],\n",
    "                           var_name='treatment', value_name='dose')\n",
    "treatments_clean = treatments_clean[treatments_clean.dose != \"-\"]\n",
    "treatments_clean['dose_start'], treatments_clean['dose_end'] = treatments_clean['dose'].str.split(' - ', 1).str\n",
    "treatments_clean = treatments_clean.drop('dose', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "treatments_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adverse reaction should be part of the `treatments` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_join_merge_dataframe.html) for the function used in the solution.*\n",
    "\n",
    "Merge the adverse_reaction column to the treatments table, joining on given name and surname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "treatments_clean = pd.merge(treatments_clean, adverse_reactions_clean,\n",
    "                            on=['given_name', 'surname'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "treatments_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given name and surname columns in `patients` table duplicated in `treatments` and `adverse_reactions` tables  and Lowercase given names and surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_join_merge_dataframe.html) for one function used in the solution and [tutorial](http://erikrood.com/Python_References/dropping_rows_cols_pandas.html) for another function used in the solution.*\n",
    "\n",
    "Adverse reactions table is no longer needed so ignore that part. Isolate the patient ID and names in the patients table, then convert these names to lower case to join with treatments. Then drop the given name and surname columns in the treatments table (so these being lowercase isn't an issue anymore)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "id_names = patients_clean[['patient_id', 'given_name', 'surname']]\n",
    "id_names.given_name = id_names.given_name.str.lower()\n",
    "id_names.surname = id_names.surname.str.lower()\n",
    "treatments_clean = pd.merge(treatments_clean, id_names, on=['given_name', 'surname'])\n",
    "treatments_clean = treatments_clean.drop(['given_name', 'surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "treatments_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient ID should be the only duplicate column\n",
    "all_columns = pd.Series(list(patients_clean) + list(treatments_clean))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Complete the remaining \"Quality\" **Define, Code, and Test** sequences after watching the *\"Cleaning for Quality\"* video.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip code is a float not a string and Zip code has four digits sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: see the \"Data Cleaning Process\" page.*\n",
    "\n",
    "Convert the zip code column's data type from a float to a string using astype, remove the '.0' using string slicing, and pad four digit zip codes with a leading 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean.zip_code = patients_clean.zip_code.astype(str).str[:-2].str.pad(5, fillchar = '0')\n",
    "# Reconvert NaNs entries that were converted to '0000n' by code above\n",
    "patients_clean.zip_code = patients_clean.zip_code.replace('0000n', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean.zip_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tim Neudorf height is 27 in instead of 72 in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here.*\n",
    "Replace height for rows in the patients table that have a height of 27 in (there is only one) with 72 in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean.height = patients_clean.height.replace(27, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "# Should be empty\n",
    "patients_clean[patients_clean.height == 27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full state names sometimes, abbreviations other times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_apply_operations_to_dataframes.html) for method used in solution.*\n",
    "\n",
    "Apply a function that converts full state name to state abbreviation for California, New York, Illinois, Florida, and Nebraska."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "# Mapping from full state name to abbreviation\n",
    "state_abbrev = {'California': 'CA',\n",
    "                'New York': 'NY',\n",
    "                'Illinois': 'IL',\n",
    "                'Florida': 'FL',\n",
    "                'Nebraska': 'NE'}\n",
    "\n",
    "# Function to apply\n",
    "def abbreviate_state(patient):\n",
    "    if patient['state'] in state_abbrev.keys():\n",
    "        abbrev = state_abbrev[patient['state']]\n",
    "        return abbrev\n",
    "    else:\n",
    "        return patient['state']\n",
    "    \n",
    "patients_clean['state'] = patients_clean.apply(abbreviate_state, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dsvid Gustafsson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here.*\n",
    "\n",
    "Replace given name for rows in the patients table that have a given name of 'Dsvid' with 'David'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean.given_name = patients_clean.given_name.replace('Dsvid', 'David')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean[patients_clean.surname == 'Gustafsson']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erroneous datatypes (assigned sex, state, zip_code, and birthdate columns) and Erroneous datatypes (auralin and novodra columns) and The letter 'u' in starting and ending doses for Auralin and Novodra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [documentation page](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.astype.html) for one method used in solution, [documentation page](http://pandas.pydata.org/pandas-docs/version/0.20/generated/pandas.to_datetime.html) for one function used in the solution, and [documentation page](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.strip.html) for another method used in the solution.*\n",
    "\n",
    "Convert assigned sex and state to categorical data types. Zip code data type was already addressed above. Convert birthdate to datetime data type. Strip the letter 'u' in start dose and end dose and convert those columns to data type integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "# To category\n",
    "patients_clean.assigned_sex = patients_clean.assigned_sex.astype('category')\n",
    "patients_clean.state = patients_clean.state.astype('category')\n",
    "\n",
    "# To datetime\n",
    "patients_clean.birthdate = pd.to_datetime(patients_clean.birthdate)\n",
    "\n",
    "# Strip u and to integer\n",
    "treatments_clean.dose_start = treatments_clean.dose_start.str.strip('u').astype(int)\n",
    "treatments_clean.dose_end = treatments_clean.dose_end.str.strip('u').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple phone number formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: helpful [Stack Overflow answer](https://stackoverflow.com/a/123681).*\n",
    "\n",
    "Strip all \" \", \"-\", \"(\", \")\", and \"+\" and store each number without any formatting. Pad the phone number with a 1 if the length of the number is 10 digits (we want country code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean.phone_number = patients_clean.phone_number.str.replace(r'\\D+', '').str.pad(11, fillchar='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean.phone_number.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default John Doe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Recall that it is assumed that the data that this John Doe data displaced is not recoverable.*\n",
    "\n",
    "Remove the non-recoverable John Doe records from the patients table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "patients_clean = patients_clean[patients_clean.surname != 'Doe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "# Should be no Doe records\n",
    "patients_clean.surname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be no 123 Main Street records\n",
    "patients_clean.address.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple records for Jakobsen, Gersten, Taylor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here.*\n",
    "\n",
    "Remove the Jake Jakobsen, Pat Gersten, and Sandy Taylor rows from the patients table. These are the nicknames, which happen to also not be in the treatments table (removing the wrong name would create a consistency issue between the patients and treatments table). These are all the second occurrence of the duplicate. These are also the only occurences of non-null duplicate addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "# tilde means not: http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n",
    "patients_clean = patients_clean[~((patients_clean.address.duplicated()) & patients_clean.address.notnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "patients_clean[patients_clean.surname == 'Jakobsen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean[patients_clean.surname == 'Gersten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean[patients_clean.surname == 'Taylor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kgs instead of lbs for Zaitseva weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here.*\n",
    "\n",
    "Use advanced indexing to isolate the row where the surname is Zaitseva and convert the entry in its weight field from kg to lbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your cleaning code here\n",
    "weight_kg = patients_clean.weight.sort_values()[0]\n",
    "mask = patients_clean.surname == 'Zaitseva'\n",
    "column_name = 'weight'\n",
    "patients_clean.loc[mask, column_name] = weight_kg * 2.20462"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your testing code here\n",
    "# 48.8 shouldn't be the lowest anymore\n",
    "patients_clean.weight.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
